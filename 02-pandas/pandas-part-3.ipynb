{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas part 3: Grouping data and merging tables\n",
    "\n",
    "Notebook developed by Sam Maurer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we'll use a set of data about buildings and households in San Francisco. It's in [HDF format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format), which is a way of storing data on disk that similar to a database.\n",
    "\n",
    "I'm having trouble loading this data directly from a URL, so instead we'll have Python download the file and save it into the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/urbansim/urbansim_parcels/raw/master/sf_example/data/sanfran_public.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  #  third-party library for making HTTP requests\n",
    "r = requests.get(url)  # gets everything (data + metadata) that a web browser would\n",
    "open('sanfran_public.h5', 'wb').write(r.content)  # saves content to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HDF file can contain more than one table. Let's see what they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore('sanfran_public.h5')\n",
    "print(hdf.keys())\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load these tables as DataFrames one at a time.\n",
    "\n",
    "### New function -- `pd.read_hdf()`, documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_hdf.html)\n",
    "- arguments: a filename or URL, and the name of a table inside the file\n",
    "- returns: a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = pd.read_hdf('sanfran_public.h5', 'buildings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice:\n",
    "\n",
    "1. Unlike when we read a CSV, the DataFrame's index now has a **name**. And its values are **not sequential**. This was set up before the data was saved, and the HDF format preserves it.\n",
    "\n",
    "  DataFrame indexes are different from normal columns. In some ways you can treat them like regular data, but often not. To remove the index's special properties, you can copy the values into a separate column, or run `.reset_index()` on the DataFrame.\n",
    "  \n",
    "  \n",
    "  \n",
    "2. Does anything strike you about the data values in the table?\n",
    "\n",
    "### Review\n",
    "\n",
    "Try using `.describe()` to get some descriptive statistics about the buildings.\n",
    "\n",
    "Then use `.plot.hist()` to make histograms of some of the variables.\n",
    "\n",
    "Remember that you can filter data using `.loc[<expression>]` to make the histogram clearer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get rid of the scientific notation\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grouping data\n",
    "\n",
    "Often you'll want to divide your data into categories while analyzing it. You can always do this manually with filter expressions, but Pandas also has tools to do it automatically.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/waddell/CP255/master/05-data-manipulation/img/groupby.png' height=\"800\" width=\"500\">\n",
    "\n",
    "### New function -- `.groupby()`, documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.groupby.html)\n",
    "- call from: a DataFrame\n",
    "- arguments: name of a column representing groups\n",
    "- returns: a special \"grouped\" DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.loc[buildings.stories<7].groupby('stories').residential_units.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review that syntax piece by piece:\n",
    "\n",
    "- `buildings` --> a DataFrame\n",
    "- `buildings.loc[buildings.stories<7]` --> only rows with <7 stories\n",
    "- `.groupby('stories')` --> divide the data into groups for further analysis\n",
    "- `.residential_units` --> focus on a single column\n",
    "- `.describe()` --> descriptive statistics broken down by group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What years were buildings of different heights constructed? All you need to do is replace one of the column names from the previous line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this line of code to add a column listing the decade of construction: \n",
    "\n",
    "`buildings['decade'] = (buildings.loc[buildings.year_built<2010].year_built//10)*10`\n",
    "\n",
    "Re-group the data using the new variable. What can you learn about what's been built over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging data\n",
    "\n",
    "Sometimes you'll want to merge information together from more than one DataFrame. This is a common operation when data is divided into multiple, relational tables like in a database.\n",
    "\n",
    "The best way to start is to think about the hierarchy of the data tables you're working with. For example:\n",
    "\n",
    "- multiple *households* go into a *building*\n",
    "- multiple *buildings* go into a *census tract*\n",
    "- multiple *census tracts* go into a *county*\n",
    "\n",
    "The most common type of merge looks like this: For each row of data about the **finer-grained thing**, use an ID to look up information about the associated **coarser thing**, and add the information as new columns.\n",
    "\n",
    "### New function -- `pd.merge()`, documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.merge.html)\n",
    "- arguments: two source DataFrames, ids to use for joining, instructions on how to merge\n",
    "- returns: a new DataFrame\n",
    "\n",
    "### Loading more data: households\n",
    "\n",
    "To try this out, we'll load a second table with data about households in San Francisco. Note that these are **not real households**! The data is what's called a \"synthetic population\", where individual households are created algorithmically to match the known demographic characteristics of each census tract. In aggregate, the association between people and buildings will be realistic, but the individual data points are fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households = pd.read_hdf('sanfran_public.h5', 'households')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging coarse-to-fine (one-to-many)\n",
    "\n",
    "Multiple **households** are in each **building**. And we see that each household has a `building_id` associated with it. \n",
    "\n",
    "This means that we're able to merge characteristics of the **buildings** directly onto the **households** table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_households = pd.merge(households, buildings, on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_households.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging fine-to-coarse (many-to-one)\n",
    "\n",
    "What if we want to bring information from the **households** table over to the **buildings** table? This is harder! \n",
    "\n",
    "Because there are multiple households in each building, we have to **summarize** the information first: calculate a sum, or a mean, or even just pick the first value.\n",
    "\n",
    "But **`.groupby()`** can help us with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_totals = households.groupby('building_id').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_buildings = pd.merge(buildings, household_totals, on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_buildings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise!\n",
    "\n",
    "What can you learn from the merged data? Here are some things you might look at:\n",
    "\n",
    "- How do people's incomes vary by housing tenure? (\"Tenure\" means rent/own in this context.) Can you use this to guess which tenure category is which?\n",
    "  \n",
    "\n",
    "- How does the tenure split vary by decade of construction?\n",
    "  \n",
    "\n",
    "- Do higher-income households tend to live in larger buildings or in smaller buildings?\n",
    "  \n",
    "\n",
    "- What's the total population in single-family homes vs. multi-unit buildings? (You'll need to summarize the households with `.sum()` to count the people.)\n",
    "  \n",
    "\n",
    "- How has the square footage of units changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
