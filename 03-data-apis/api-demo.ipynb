{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data-access APIs over the web\n",
    "\n",
    "Notebook developed by Sam Maurer\n",
    "\n",
    "In Part 1, we'll load and parse results from an API feed of earthquake data.  \n",
    "In Part 2, we'll add query parameters to the workflow, using the Google Maps Geolocation API as an example.  \n",
    "In Part 3, we'll use an authenticated API to query public Twitter posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reading from an automated data feed\n",
    "\n",
    "### USGS real-time earthquake feeds\n",
    "\n",
    "This is an API for near-real-time data about earthquakes. Data is provided in JSON format over the web. No authentication is needed, and there's no way to customize the output. Instead, the API has a separate endpoint for each permutation of the data that users might want.\n",
    "\n",
    "**API documentation:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "**Sample API endpoint, for magnitude 4.5+ earthquakes in past day:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_day.geojson  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json      # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "\n",
    "import pprint    # library for cleanly printing Python data structures\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data on magnitude 2.5+ quakes from the past week\n",
    "\n",
    "endpoint_url = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "response = requests.get(endpoint_url)\n",
    "results = response.text\n",
    "\n",
    "# what's the data type of the results?\n",
    "\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New syntax -- `<list>[<position>]` and `<list>[<start>:<end>]`, RealPython tutorial [here](https://realpython.com/python-lists-tuples/)\n",
    "\n",
    "In Python, you can retrieve an item from a list by referring to its position, using integers to enumerate the items. Counting begins with 0, as in most programming languages.\n",
    "\n",
    "You can also get multiple consecutive items: `my_list[0:10]` will give you the first 10. (You get from item `0` to just *before* item `10`). And you can leave out an argument if you want to start at the beginning, or continue to the end.\n",
    "\n",
    "The same syntax works with other data types that are similar to lists, like DataFrames or strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 500 characters to see a sample of the data\n",
    "\n",
    "print(results[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like the results are a string with JSON-formatted data inside\n",
    "\n",
    "# parse the string into a Python dictionary\n",
    "data = json.loads(results)  # loads = \"load string\"\n",
    "\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New data type -- `dict`, RealPython tutorial [here](https://realpython.com/python-dicts/)\n",
    "\n",
    "A \"dictionary\" in Python contains key-value pairs, where the keys are (usually) strings and the values can be anything. Each value must be a single \"item\", but the item can contain other things -- it could be a list, or even an entire nested dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dictionary\n",
    "\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New syntax -- `<dict>['<key>']`, RealPython tutorial [here](https://realpython.com/python-dicts/)\n",
    "\n",
    "You can access elements of a dictionary using the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list of quakes to a new variable\n",
    "\n",
    "quakes = data['features']\n",
    "\n",
    "# print the most recent quake\n",
    "\n",
    "pp.pprint(quakes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New syntax -- `for <item> in <list>:`, RealPython tutorial [here](https://realpython.com/python-for-loop/)\n",
    "\n",
    "This creates a *loop*, running the subsequent indended code for each item in the list. `<list>` is the name of the list, and `<item>` is a new variable name you provide, which will refer to each item in turn as the loop runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the title from each earthquake listing\n",
    "\n",
    "for q in quakes:\n",
    "    print(q['properties']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New syntax -- `[<code> for <item> in <list>]`, RealPython tutorial [here](https://realpython.com/list-comprehension-python/)\n",
    "\n",
    "This is a shortcut to create a new list where each item from an existing list is modified using a small piece of code. Just like with the `for` syntax, `<list>` is the name of a list and `<item>` is a new variable that will refer to each item in turn. The `<code>` should do something with the item variable.\n",
    "\n",
    "This syntax is called \"list comprehension\". It can be hard to read, so I don't use it very much. But there are certain things it's really helpful for -- like parsing dictionary data into a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out magnitudes and depths into a Pandas dataframe\n",
    "\n",
    "d = {'magnitude': [q['properties']['mag'] for q in quakes],\n",
    "     'depth': [q['geometry']['coordinates'][2] for q in quakes]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# how many earthquakes were loaded into the dataframe?\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first few lines of data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some descriptive statistics\n",
    "\n",
    "pd.set_option(\"display.precision\", 1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the depth vs. magnitude\n",
    "\n",
    "df.plot(x='magnitude', y='depth', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Querying an API endpoint\n",
    "\n",
    "### Mapbox Geocoding API\n",
    "\n",
    "Services like Google Maps and Mapbox have various APIs that let you access its services through code instead of through GUI apps. This one from Mapbox lets you look up the latitude-longitude coordinates of street addresses.\n",
    "\n",
    "It works similarly to the earthquakes example, but with query parameters added to the URL endpoint!\n",
    "\n",
    "**API documentation:**  \n",
    "https://www.mapbox.com/api-documentation/#geocoding\n",
    "\n",
    "**API endpoint:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places\n",
    "\n",
    "**API endpoint with query parameters:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places/Wurster+Hall.json?access_token=pk.eyJ1IjoiY3AyNTVkZW1vIiwiYSI6ImRPcTlnTUEifQ.3C0d0Nk_rcwV-8JF29PU-w\n",
    "\n",
    "You can get your own access key by signing up for a Mapbox account, if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json      # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "\n",
    "import pprint    # library for cleanly printing Python data structures\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to encode the search query so that it can be passed as a URL, \n",
    "# with spaces and other special characters removed\n",
    "\n",
    "endpoint = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n",
    "\n",
    "address = 'Wurster Hall'\n",
    "\n",
    "params = {'limit': 1,\n",
    "          'access_token': 'pk.eyJ1IjoiY3AyNTVkZW1vIiwiYSI6ImRPcTlnTUEifQ.3C0d0Nk_rcwV-8JF29PU-w'}\n",
    "\n",
    "url = requests.Request('GET', endpoint+address+'.json', params=params).prepare().url\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and parse the results\n",
    "\n",
    "response = requests.get(url)\n",
    "results = response.text\n",
    "data = json.loads(results)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print it more nicely\n",
    "\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the lat-lon coordinates\n",
    "\n",
    "for r in data['features']:\n",
    "    coords = r['geometry']['coordinates']\n",
    "    print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Search for some other addresses or landmarks!\n",
    "2. Take a look at the [API documentation](https://www.mapbox.com/api-documentation/#geocoding). Can you figure out how to retrieve other points of interest near Wurster Hall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Querying an API with back-and-forth authentication\n",
    "\n",
    "### Twitter search APIs\n",
    "\n",
    "Twitter's APIs operate over the web as well, but they require a back-and-forth authentication process at the beginning of each connection. It's easier to have a Python library handle this than to create the query URLs ourselves.\n",
    "\n",
    "Most Twitter APIs perform stand-alone operations: you submit a query and receive results, like in earlier examples. Twitter also has a \"streaming\" API that continues sending results in real time until you disconnect.\n",
    "\n",
    "**API documentation:**  \n",
    "https://developer.twitter.com/en/docs/tweets/search/overview\n",
    "\n",
    "**Documentation for the Python helper library**:  \n",
    "http://geduldig.github.io/TwitterAPI/\n",
    "\n",
    "### Setup\n",
    "\n",
    "This part of the demo requires a file of account credentials called `keys.py`. You'll find the file in a bCourses announcement -- download it and put it into the same DataHub folder as this notebook. \n",
    "\n",
    "Instructions [here](https://github.com/smmaurer/api-demo/blob/master/README.md) for generating your own credential tokens later on, if you'd like to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New syntax -- `!pip install <library_name>`\n",
    "\n",
    "In a Jupyter notebook, beginning a line with `!` passes the instruction directly to the computer's operating system instead of running it with Python.\n",
    "\n",
    "This particular command uses a program called Pip, which is a tool for managing Python libraries. `pip install` searches Pip's index for the library and then automatically downloads and installs it.\n",
    "\n",
    "In DataHub, the Python libraries are reset every time you log in. So you'll have to install any special ones each time you begin a new session. But if you run this notebook on your own computer, new libraries will stay installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install TwitterAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API credentials from keys.py file in the\n",
    "# same directory as this notebook\n",
    "\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an API connection using credentials from the keys file\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, \n",
    "                 access_token, access_token_secret)\n",
    "\n",
    "print(\"Connection is set up but not tested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simple data request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent tweet from CED\n",
    "\n",
    "endpoint = 'statuses/user_timeline'\n",
    "params = {\n",
    "    'screen_name': 'wursterlife', \n",
    "    'count': 1\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what other data is there?\n",
    "\n",
    "pp.pprint(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other API endpoints allow different types of searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for recent tweets with your favorite emoji (or any other text string)\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': 'ðŸ’˜', \n",
    "    'count': 5\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for public tweets in Korean\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'lang': 'ko', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for public tweets geotagged near the UC Berkeley campus\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'geocode': '37.873,-122.260,0.5km', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Try some different search queries!\n",
    "2. Display some more data fields in addition to the tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Streaming live tweets in real time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter allows only one or two simultaneous streaming connections for \n",
    "# each set of API credentials, so this part may not work during class\n",
    "\n",
    "endpoint = 'statuses/filter'\n",
    "params = {'locations': '-180,-90,180,90'}\n",
    "r = api.request(endpoint, params)\n",
    "LIMIT = 20\n",
    "\n",
    "# 'enumerate' lets us count tweets as we receive them\n",
    "\n",
    "for i, tweet in enumerate(r.get_iterator()):\n",
    "    print(tweet['created_at'])\n",
    "    print(tweet['place']['full_name'] + ', ' + tweet['place']['country'])\n",
    "    print(tweet['text'] + '\\n')\n",
    "    if (i > LIMIT): break\n",
    "\n",
    "# close the streaming connection\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises for the remainder of class\n",
    "\n",
    "Choose your favorite:\n",
    "\n",
    "1. Make a scatter plot of the lat-lon coordinates of earthquakes.  \n",
    "   &nbsp;\n",
    "   \n",
    "2. The earthquakes API is actually returning a specific data format called [GeoJSON](https://en.wikipedia.org/wiki/GeoJSON), also used by many other geospatial data feeds. Try saving the raw GeoJSON file and opening it in QGIS or in the [geojson.io](http://geojson.io) web viewer.  \n",
    "   &nbsp;\n",
    "\n",
    "2. Using the geocoding example as a starting point, try searching Mapbox's Directions API or Elevation API instead. You can read more about them on the [Mapbox API documentation page](https://www.mapbox.com/api-documentation/#introduction).  \n",
    "   &nbsp;\n",
    "\n",
    "3. Try out another API that you're interested in. Can you figure out how to connect to it using Python?  \n",
    "\n",
    "   With municipal data it's often easiest to just download a data file, but APIs are great for querying big data sets or tracking live updates. Here are some resources.\n",
    "\n",
    "   - San Francisco:  https://data.sfgov.org/developers  \n",
    "   - Alameda County:  https://data.acgov.org/developers  \n",
    "   - UC Berkeley:  https://api-central.berkeley.edu  \n",
    "   - US Census:  http://www.census.gov/data/developers/data-sets.html  \n",
    "   - Open Data Network:  https://www.opendatanetwork.com  \n",
    "   - CivicData:  http://www.civicdata.io/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
